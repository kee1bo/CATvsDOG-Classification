{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613e8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d81d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eeac89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), #0-255 to 0-1,  numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1], formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c16907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader ; since it is unreliable and not possible to load all data at once, we use dataloaders\n",
    "train_path = 'train/' \n",
    "test_path = 'test/'\n",
    "\n",
    "trainLoader = DataLoader(\n",
    "                torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "                batch_size=256,shuffle=True)\n",
    "\n",
    "testLoader = DataLoader(\n",
    "                torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "                batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd398044",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path(train_path)\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7f2852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats', 'dogs']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3acfa336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write CNN\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=2):\n",
    "        super(ConvNet,self).__init__()\n",
    "        #output side after convolution filter\n",
    "        \n",
    "        # Input Shape = (256,3,150,150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=12,kernel_size =3 ,stride=1,padding=1)\n",
    "        \n",
    "        #shape = (256,12,150,150)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 12)\n",
    "        #shape = (256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #shape = (256,12,150,150)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2)\n",
    "        #reduce the  image size by a factor of 2\n",
    "        #shape = (256,12,75,75)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20,kernel_size=3, stride=1,padding=1)\n",
    "        #shape =  (256,20,75,75)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        #shape = (256,12,150,150)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20,out_channels=32,kernel_size =3 ,stride=1,padding=1)\n",
    "        \n",
    "        #shape = (256,32,150,150)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm2d(num_features = 32)\n",
    "        #shape = (256,32,150,150)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #shape = (256,32,150,150)\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(in_features=32*75*75,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        #Feed Forward Function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "        output = self.pool(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "            \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "            \n",
    "            \n",
    "            # above output will be in matrix form, with shape(256,32,75,75)\n",
    "            \n",
    "        output = output.view(-1,32*75*75)\n",
    "\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b1a2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b868243",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(),lr=0.01,weight_decay=0.001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d72eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac1660a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the size of training and testing images\n",
    "\n",
    "train_count = len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count = len(glob.glob(test_path+'/**/*.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fceae35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count,test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e40783a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0Train Loss: 37Train Accuracy:0.51915Test Accuracy:0.5\n",
      "Epoch: 1Train Loss: 0Train Accuracy:0.4998Test Accuracy:0.4998\n",
      "Epoch: 2Train Loss: 0Train Accuracy:0.5015Test Accuracy:0.5002\n",
      "Epoch: 3Train Loss: 0Train Accuracy:0.4971Test Accuracy:0.5\n",
      "Epoch: 4Train Loss: 0Train Accuracy:0.49365Test Accuracy:0.4998\n",
      "Epoch: 5Train Loss: 0Train Accuracy:0.49875Test Accuracy:0.4998\n",
      "Epoch: 6Train Loss: 0Train Accuracy:0.5021Test Accuracy:0.4994\n",
      "Epoch: 7Train Loss: 0Train Accuracy:0.50145Test Accuracy:0.4998\n",
      "Epoch: 8Train Loss: 0Train Accuracy:0.50285Test Accuracy:0.5\n",
      "Epoch: 9Train Loss: 0Train Accuracy:0.4973Test Accuracy:0.5\n"
     ]
    }
   ],
   "source": [
    "#Model Training and Saving best model\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Evalutaion and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "\n",
    "    for i, (images,labels) in enumerate(trainLoader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        outputs= model(images)\n",
    "        \n",
    "        loss = loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss += loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy += int(torch.sum(prediction==labels.data))\n",
    "            \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss = train_loss/train_count\n",
    "    \n",
    "            \n",
    "    # Evaluation on Test dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy = 0.0\n",
    "    for i, (images,labels) in enumerate(testLoader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        outputs = model(images)\n",
    "        \n",
    "        \n",
    "#         train_loss += loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        test_accuracy += int(torch.sum(prediction==labels.data))\n",
    "            \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "#     test_loss = train_loss/test_count \n",
    "\n",
    "    print('Epoch: ' + str(epoch)+'Train Loss: '+str(int(train_loss)) + 'Train Accuracy:'+str(train_accuracy)+ 'Test Accuracy:'+ str(test_accuracy))\n",
    "    \n",
    "          \n",
    "          \n",
    "    #save the besst\n",
    "          \n",
    "    if test_accuracy>best_accuracy:\n",
    "          torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "          best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
